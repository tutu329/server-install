1、关于kvcache的量化
    1）下载最新qwen和model
    2）model下的cache_autogptq_cuda_256.cpp和cache_autogptq_cuda_kernel_256.cu复制到qwen目录下
    3）修改openai_api.pyRuntimeError: Ninja is required to load C++ extensions
        model = AutoModelForCausalLM.from_pretrained(
            args.checkpoint_path,
            device_map=device_map,
            trust_remote_code=True,
            use_cache_quantization=True,
            use_cache_kernel=True,
            use_flash_attn=False,
            resume_download=True,
        ).eval()

2、RuntimeError: Ninja is required to load C++ extensions
    1）git clone https://github.com/ninja-build/ninja
    2）git checkout release
    3）win搜索vs，执行开始菜单中visual studio 2022下的x64 native tools command prompt（注意不是x86！）
        4）进入ninja文件夹
        5）conda activate qwen(也可能不需要)
        6）python ./configure.py --bootstrap
        7）运行ninja： ninja: no work to do.
        8）qwen下，运行python openai_api.py
        报错：
            无法打开包括文件: “assert.h”
            无法打开包括文件: “corecrt.h”等
        解决：a）visual studio installer中，安装windows 11 sdk和 MSVC生成工具
             b）set include=C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.37.32822\include;C:\Program Files (x86)\Windows Kits\10\Include\10.0.22621.0\ucrt;C:\Program Files (x86)\Windows Kits\10\Include\10.0.22621.0\shared
             c）然后qwen下，运行python openai_api.py
        报错：error: invalid redeclaration of type name "size_t"（这个错误就是因为误用了x86 native tools command prompt，要改用x64）
        然后运行正常！




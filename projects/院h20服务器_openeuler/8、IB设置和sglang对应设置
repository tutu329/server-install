1、官网下载安装cuda-toolkit（包含驱动和运行库）
    此时nvidia-smi和nvcc -V正常
2、安装nvidia-driver-libs和nvidia-fabric-manager
    此时torch.cuda.is_available()才正常
3、安装gcc、g++
    如果sglang运行报错如：gcc: fatal error: cannot execute ‘cc1plus’: execvp: No such file or directory
        1）确保cuda-toolkit安装正常(nvcc)
        2）确保gcc、g++安装正常(gcc和cc1plus)
    涉及gcc、g++重新安装的解决办法：
        sudo apt install --reinstall build-essential g++ gcc
4、IB环境安装
    基本配置：
        1）安装IB驱动（后续官方仅维护DOCA-ofed，安装老的mlnx_ofed也可以）
            DOCA-ofed：https://developer.nvidia.com/doca-downloads（Host-Server->DOCA-Host->Linux->x86_64->doca-ofed->对应linux）
            mlnx_ofed:https://network.nvidia.com/products/infiniband-drivers/linux/mlnx_ofed/
        2）安装工具
            sudo apt update
            sudo apt install -y opensm infiniband-diags rdma-core ibverbs-utils ibutils
        3）物理联通情况
            a）查看交换机是否均为绿灯
            b)rdma link show（查看连通情况和roce/ib模式）
        4)IB网卡的IB模式的确认
            若为roce（Ethernet）模式，切换为ib模式：
                sudo apt install mstflint
                sudo mst start
                mst status
                sudo mlxconfig -d /dev/mst/mt4123_pciconf0 q | grep LINK_TYPE
                sudo mlxconfig -d /dev/mst/mt4123_pciconf0 set LINK_TYPE_P1=1 LINK_TYPE_P2=1
                sudo mlxfwreset -d /dev/mst/mt4123_pciconf0 --yes 或者 sudo reboot
        5）启动opensm（opensm是ib网联通的关键，且只有一个节点需要启动opensm）
            sudo systemctl status opensm
            sudo systemctl start opensm
            sudo systemctl enable opensm
    测试环境：
        apt install perftest
    测试：
        服务器1：ib_write_bw -F --report_gbits
        服务器2：ib_write_bw -F 服务器1的IP --report_gbits
5、sglang设置（节点0，节点1把rank改为1、模型路径改掉即可）
    1)几个关键点：
        a）NCCL_IB_HCA用于指定并行通信的IB口，NCCL_SOCKET_IFNAME和GLOO_SOCKET_IFNAME只是指定发起握手通信的网口（所以一个就行）
        b）NCCL_IB_GID_INDEX=3在roce环境下很关键（roce下系统默认情况会找错GID，GID可通过show_gids查看），ib不一定需要
        c）tp 16是2台服务器并行推理的关键
        d）mem-fraction-static是sglang预分配多少显存给模型，max-total-tokens是给模型分配多大的上下文空间（对显存容量影响较大），max-running-requests就是给模型开多大的并发访问数
        e）enable-torch-compile、enable-ep-moe和speculative是sglang对deepseek-r1这类模型的关键加速（单节点推理时，这几个参数影响很大，双节点不清楚为何没影响，还需要测试，可能和IB有关）
    2)2node-ds-r1-671b-8.sh：
        export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
        export SGL_ENABLE_JIT_DEEPGEMM=1
        export NCCL_IB_HCA=mlx5_0,mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7
        # export NCCL_IB_GID_INDEX=3

        export NCCL_SOCKET_IFNAME=ens19f0np0
        export GLOO_SOCKET_IFNAME=ens19f0np0

        source /home/tutu/miniconda3/etc/profile.d/conda.sh
        conda activate sgl45
        python -m sglang.launch_server --served-model-name=ds-r1-671b --model-path=/home/tutu/models/DeepSeek-R1 \
        --enable-p2p-check \
        --reasoning-parser=deepseek-r1 --trust-remote-code \
        --tp 16 \
        --dist-init-addr 192.168.88.1:28002 \
        --nnodes 2 \
        --node-rank 0 \
        --host=0.0.0.0 --port=28001 \
        --mem-fraction-static=0.7 \
        --max-total-tokens=65000 --max-running-requests=64 \
        # --enable-dp-attention \
        # --quantization fp8 \
        # --enable-flashmla \
        # --enable-nccl-nvls \
        # --enable-deepep-moe \
        # --deepep-mode=auto \
        # --disable-cuda-graph \
        # --disable-radix-cache \
        # --cuda-graph-max-bs=128 \
        # --attention-backend=fa3 \
        --enable-torch-compile --torch-compile-max-bs 1 \
        --enable-ep-moe \
        --speculative-algorithm EAGLE3 \
        # --speculative-algo NEXTN \
        --speculative-draft /home/zsoft/models/DeepSeek-R1-NextN \
        --speculative-num-steps 2 \
        --speculative-eagle-topk 4 \
        --speculative-num-draft-tokens 4

6、llm的api调用测试
    curl -X POST http://10.150.66.10:30000/v1/chat/completions \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -d '{
        "model": "gpt-4o-mini",
        "messages": [
          {"role": "system", "content": "You are a helpful assistant."},
          {"role": "user", "content": "你好，世界！"}
        ],
        "temperature": 0.7,
        "max_tokens": 150
      }'

7、rdma_speed_ib.sh(用于实时监测8个ib网卡的流量，用于推理和训练的调试、优化)
    #!/usr/bin/env bash
    DEVICES=(mlx5_0 mlx5_1 mlx5_2 mlx5_3 mlx5_4 mlx5_5 mlx5_6 mlx5_7)
    PORT=1
    INTERVAL=5

    bytes(){ cat /sys/class/infiniband/$1/ports/$PORT/counters/$2; }

    while true; do
      declare -A TX1 RX1 TX2 RX2
      for D in "${DEVICES[@]}"; do
          RX1[$D]=$(bytes $D port_rcv_data)
          TX1[$D]=$(bytes $D port_xmit_data)
      done
      sleep $INTERVAL
      for D in "${DEVICES[@]}"; do
          RX2[$D]=$(bytes $D port_rcv_data)
          TX2[$D]=$(bytes $D port_xmit_data)
      done

      echo "$(date '+%F %T')"
      for D in "${DEVICES[@]}"; do
          RX_B=$(( ( ${RX2[$D]} - ${RX1[$D]} ) * 4 ))   # octets→bytes
          TX_B=$(( ( ${TX2[$D]} - ${TX1[$D]} ) * 4 ))
          RX_Mbps=$(echo "scale=1; $RX_B*8/1000000/$INTERVAL" | bc)
          TX_Mbps=$(echo "scale=1; $TX_B*8/1000000/$INTERVAL" | bc)
          printf "[%-6s] RX: %6s Mb/s | TX: %6s Mb/s\n" "$D" "$RX_Mbps" "$TX_Mbps"
      done
      echo
    done
